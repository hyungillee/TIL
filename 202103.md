# 210313
## AI보안수업 2주차
 *  ai의 전반적인 흐름. 퍼셉트론, MLE 

## 랩세미나
1. Neural Attention Distillation: Erasing Backdoor Triggers from DNN, ICLR, 2021
    - Attention distillation을 사용하여 백도어 공격을 방어하는 방법을 제시한 논문. 먼저 clean 데이터로 teacher network를 fintune하고, teacher에서 복제되고 백도어된 student 모델과 activation map의 차이를 최소화하면서 벡도어트리거 지움.

2. Gaussian Process 
    - Gaussian Process에 대한 설명. 
    - Random precesss는 time dependent한 Random Varialbe의 집합이다. 시간이 일차원적인 구조를 가지니 랜덤프로세스라 부르고, 2차원적인 것과 같이 쓰이면 랜덤 필드라고 함.
    - 각 타임포인트에 대해서 가우시안 분포 하나가 있을 것이고 평균과 공분산이 존재할 것이다. 그리고 무한대의 많은 t가 있으면 무핸개의 Mean과 Conv 벡터가 있을 것이다. GP라는 함수는 각 지점의 함수값이 가우시안 분포를 따르는 모든 함수들의 집합이다. 특정 지점의 mean과 Conv 의 정보를 돌려주는 함수의 역할을 한다. GP의 관건은 Mean function과 무한개의 지점에 대해 정보를 제공하는 Conv function을 가지고 어떻게 inference할지 연산에 있다
    - Conv 행렬로는 연산하기가 어렵기 때문에 커널행렬로 바꾸는 작업을 한다. 커널행렬은 관측 포인트의 갯수만큼 행렬이 나온다.  대표적으로 Squared Exponential kernel 이라는 식을 사용한다(RBF라고도 함). 툴에 넣으면 쉽게 사용할 수 있지만 머학원 수준에는 유도과정을 증명할 수 있어야한다. 
    - GP의 관건은 효과적으로 infer을 할 수 있다. 하이퍼 파라미터 튜닝할 때, 차원이 적을때, 약 10개미만 정도일 때 GP가 효과적일 수 있다.

3. Practical No-box Adversarial Attaacks against DNNs, NeurIPS, 2020
- Deep neural network의 adversarial attack 방법 중 no-box 공격 기법을 제시한 논문. NO-BOX를 통해 좀더 현실적인 관점에서 adversarial example attack을 제시함. 공격대상의 쿼리가 없고 데이터셋의 크기 제한이 있고 Transferability 특징을 이용한 환경에서 공격이 이루어진다. 데이터 증강과 함께 convolution autoencoder 기반으로 adver example을 생성함.
- 이미지 분야의 classifer은 피처를 추출하여 피처기반으로 분류한다. 다른 클래스의 피처만 잘 추출하면 adversarial example또한 만들기가 가능한 것이다. 타겟모델을 사용하지 않고 타겟모델이 사용한 데이터만 가지고 공격을 시도함. 기존의 whitebox blackbox 관념을 깨는 현실적인 상황에서의 공격을 제시하는 논문.

##  Selenium 연습

# 210314
*  수업 복습,  랩세미나 정리
*  논문: DECISION-BASED ADVERSARIAL ATTACKS: RELIABLE ATTACKS AGAINST BLACK-BOX MACHINE LEARNING MODELS (ICLR 2018)

# 210315
* Lecture: 네트워크개론, 패턴인식
* 패턴인식 복습
    - loss matrix를 통해 RV의 패널티를 가해서 결정경계 이동시킴.
    - 두 랜덤변수간 prior같고 분산이 같은 상황에서 공분산이 같으면 Euclidean Distance 이용하고, 공분산이 다르다면(=시그마의 non-diagonal이 0이 아니라면) Mahalanobis Distance 이용한다. 
* 논문: Adversarial Robustness through Local Linearization [NIPS 2019]

# 210315

* Lecture: 암호프로그래밍
* 논문: Adversarial Robustness through Local Linearization [NIPS 2019]
    - adversarial attack 이 가해진 모델의 Loss function에 1차 테일러 근사를 하여 근처 local surface의 선형, 비선형 정도를 알 수 있다. 

* Taylor expansion in DL  

# 210315
* paper: Robustness via curvature regularization, and vice versa [openaccess 2019]
    - Adverarial training이 될 수록 loss의 curvature을 감소시킨다는 것을 증명하면서, Hessian matrix의 large eigenvalues들을 panality하는  Curvature regularization (CURE) 방어법을 제시.

* Hessian matrix: 다변수 함수의 이차미분을 나타낸 행렬. 이차미분이기에 함수의 curvature 특성을 나타냄.  Hessian matrix의 eigenvalue가 모두 양수면 해당지점에서 극소값을 가지고, 모두 음수면 극댓값, 음과 양이 섞여있으면 해당 지점에서 변곡점을 갖는다. 

* 삼성SDS 회의  
    * feature selection algothim : relief,information gain, CfsSubsetEval 
    * Order Matters: Semantic-Aware Neural
Networks for Binary Code Similarity Detection [AAAI 2020]  : binary similarity task 풀기위해 Bert GNN CNN 사용한 논문

* LIG 최종 보고서 작성

# 210316
* LIG 보고서
* 킥오프 미팅 피피티 준비
* 
